\contentsline {section}{\numberline {1}Unconstrained Optimization}{7}{section.1}%
\contentsline {subsection}{\numberline {1.1}Basic Definitions}{7}{subsection.1.1}%
\contentsline {subsubsection}{\numberline {1.1.1}Optimization in a Set}{7}{subsubsection.1.1.1}%
\contentsline {subsubsection}{\numberline {1.1.2}Minimizer}{7}{subsubsection.1.1.2}%
\contentsline {subsubsection}{\numberline {1.1.3}Stationary Point, Saddle Point}{7}{subsubsection.1.1.3}%
\contentsline {subsubsection}{\numberline {1.1.4} Conditions for Global Minimizer: (1) exists global-minimizer; (2) has the minimum value in all stationary points}{8}{subsubsection.1.1.4}%
\contentsline {subsection}{\numberline {1.2}Special Situation: Optimization in $\mathbb {R}$}{8}{subsection.1.2}%
\contentsline {subsubsection}{\numberline {1.2.1} Necessary condition of local-min: $f'(x^*)=0$}{8}{subsubsection.1.2.1}%
\contentsline {subsubsection}{\numberline {1.2.2} Sufficient condition of local-min: $f'(x^*)=0, f''(x^*)\geq 0$}{8}{subsubsection.1.2.2}%
\contentsline {subsubsection}{\numberline {1.2.3} Sufficient condition of global-min: $f'(x^*)=0$ and $f''(x)\geq 0,\forall x\in I$}{8}{subsubsection.1.2.3}%
\contentsline {subsection}{\numberline {1.3} Restriction to a Line}{9}{subsection.1.3}%
\contentsline {subsubsection}{\numberline {1.3.1} Definition: $\phi _{\vec {u}}(t)=f(\vec {x}+t\vec {u}),\ \vec {x},\vec {u}\in \mathbb {R}^n, t\in \mathbb {R}$}{9}{subsubsection.1.3.1}%
\contentsline {subsubsection}{\numberline {1.3.2}Derivatives: $\phi '_{\vec {u}}(t)=\nabla f(\vec {x}+t\vec {u})\vec {u}$, $\phi ^{''}_{\vec {u}} (t)=\vec {u}^T {Hf}(\vec {x}+t\vec {u})\vec {u}$}{9}{subsubsection.1.3.2}%
\contentsline {subsubsection}{\numberline {1.3.3}Lemma: $x^*$ is a global minimizer of $f$ $\Leftrightarrow $ $t=0$ is the global minimizer of $\phi _{\vec {u}}(t)=f(\vec {x}+t\vec {u})$, $\forall \vec {u}\in \mathbb {R}^n$}{10}{subsubsection.1.3.3}%
\contentsline {subsection}{\numberline {1.4}General: Optimization in $\mathbb {R}^n$}{10}{subsection.1.4}%
\contentsline {subsubsection}{\numberline {1.4.1}Local-min Necessary Condition $1$: $\nabla f$ is continuous, $x^*$ is a local minimizer $\Rightarrow \nabla f(x^*)=0$}{10}{subsubsection.1.4.1}%
\contentsline {subsubsection}{\numberline {1.4.2}Local-min Necessary Condition $2$: $Hf$ is continuous, $x^*$ is a local minimizer $\Rightarrow \nabla ^2 f(x^*)\succeq 0$}{11}{subsubsection.1.4.2}%
\contentsline {subsubsection}{\numberline {1.4.3}Local-min Sufficient Condition $1$: $Hf$ is continuous, $\nabla f(\vec {x}^*)=0$, $\vec {u}^T Hf(\vec {x}) \vec {u}\geq 0,\forall \vec {u}\in \mathbb {R}^n$ and $\exists r>0, \|\vec {x}-\vec {x}^*\|<r$ $\Rightarrow $ $\vec {x}^*$ is a local minimizer}{12}{subsubsection.1.4.3}%
\contentsline {subsubsection}{\numberline {1.4.4}Local-min Sufficient Condition $1'$: $Hf$ is continuous, $\nabla f(\vec {x}^*)=0$, $\nabla ^2 f(\vec {x}^*)\succ 0$ $\Rightarrow $ $\vec {x}^*$ is a local minimizer}{12}{subsubsection.1.4.4}%
\contentsline {subsubsection}{\numberline {1.4.5}Global-min Sufficient Condition: $Hf$ is continuous, $\nabla f(\vec {x}^*)=0$, $\nabla ^2f(\vec {x})\succeq 0,\forall \vec {x}$ $\Rightarrow $ $\vec {x}^*$ is a global minimizer}{12}{subsubsection.1.4.5}%
\contentsline {subsubsection}{\numberline {1.4.6}$Hf(\vec {x}^*)$ is indefinite $\Rightarrow $ $\vec {x}^*$ is saddle point}{13}{subsubsection.1.4.6}%
\contentsline {subsubsection}{\numberline {1.4.7}$Hf(\vec {x}^*)\succ 0$/$\prec 0$ $\Rightarrow $ critical point $\vec {x}^*$ is strictly local-min/local-max}{13}{subsubsection.1.4.7}%
\contentsline {subsubsection}{\numberline {1.4.8}Steps to Find Minimum in $\mathbb {R}^n$}{13}{subsubsection.1.4.8}%
\contentsline {subsection}{\numberline {1.5}Existence of Global-min}{14}{subsection.1.5}%
\contentsline {subsubsection}{\numberline {1.5.1}(Bolzano-)Weierstrass Theorem: Compact set $X$ $\Rightarrow $ $\exists $ global-min/max}{14}{subsubsection.1.5.1}%
\contentsline {subsubsection}{\numberline {1.5.2}Coercive function $f$ $\Rightarrow $ $\exists $ global-min}{14}{subsubsection.1.5.2}%
\contentsline {subsubsection}{\numberline {1.5.3}Method of finding-global-min-among-stationary-points (FGMSP)}{15}{subsubsection.1.5.3}%
\contentsline {section}{\numberline {2}Convexity}{15}{section.2}%
\contentsline {subsection}{\numberline {2.1}Convex Set}{15}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Prop: convex sets $e_1,e_2,...e_n$, then $\cap _{i=1}^ne_i$ is convex}{16}{subsubsection.2.1.1}%
\contentsline {subsection}{\numberline {2.2}Convex Hull}{16}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Convex Hull $conv(S)$ is the set of all convex combinations of points in $S$}{16}{subsubsection.2.2.1}%
\contentsline {subsubsection}{\numberline {2.2.2}Theorem: convex set $S$, convex combination $\lambda _1 x_1+\cdots +\lambda _k x_k\in S$, $\forall x_1,...,x_k\in S$}{16}{subsubsection.2.2.2}%
\contentsline {subsubsection}{\numberline {2.2.3}Corollary: $conv(S)$ is the smallest convex set containing $S$}{16}{subsubsection.2.2.3}%
\contentsline {subsection}{\numberline {2.3}Optimization over Convex Set}{17}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Convex Function}{17}{subsection.2.4}%
\contentsline {subsubsection}{\numberline {2.4.1}Definition: $f$ is convex $\Leftrightarrow $ $f(\alpha x+(1-\alpha ) y) \leq \alpha f(x)+(1-\alpha ) f(y), \forall x, y \in C, \forall \alpha \in [0,1]$}{17}{subsubsection.2.4.1}%
\contentsline {subsubsection}{\numberline {2.4.2}First-order: $f$ is convex $\Leftrightarrow $ $f(z) \geq f(x)+(z-x)^{T} \nabla f(x), \forall x, z \in C$}{17}{subsubsection.2.4.2}%
\contentsline {subsubsection}{\numberline {2.4.3}Prop: local-min$\Rightarrow \nabla f(x^*)^T(x-x^*)\geq 0,\forall x\in \&$ $\Leftrightarrow $ global-min in convex }{18}{subsubsection.2.4.3}%
\contentsline {subsubsection}{\numberline {2.4.4}Second-order: $f$ is convex $\Leftrightarrow $ $\nabla ^{2} f(x) \succeq 0,\ \forall x \in C$}{19}{subsubsection.2.4.4}%
\contentsline {subsubsection}{\numberline {2.4.5}Sufficient Condition of Strictly Convex: $\nabla ^{2} f(x) \succ 0$}{20}{subsubsection.2.4.5}%
\contentsline {subsubsection}{\numberline {2.4.6}Prop: Max and Linear combination of convex functions are also convex}{20}{subsubsection.2.4.6}%
\contentsline {subsection}{\numberline {2.5}Lemma: function $f$ is a convex function iff $\phi (t)=f(\vec {x}+t\vec {u})$ is convex of $t$}{21}{subsection.2.5}%
\contentsline {subsection}{\numberline {2.6}Proposition: Convex function $f$, $\nabla f(x^*)=0$ $\Rightarrow $ global-min}{21}{subsection.2.6}%
\contentsline {subsection}{\numberline {2.7}Application: Unconstrained Quadratic Optimization}{22}{subsection.2.7}%
\contentsline {subsection}{\numberline {2.8}Theorem: If $f$ is convex and $g$ is convex and increasing, $(g\cdot f)(x)$ is convex}{23}{subsection.2.8}%
\contentsline {subsection}{\numberline {2.9}Corollary: $f$ is linear, $g$ is convex (not necessarily increasing) $\Rightarrow $ $g\cdot f$ is convex}{24}{subsection.2.9}%
\contentsline {subsection}{\numberline {2.10}Epigraph and Jensen's Inequality}{25}{subsection.2.10}%
\contentsline {subsubsection}{\numberline {2.10.1}Def: epigraph ${epi}(f)=\{(x,y)\in C\times \mathbb {R}:y\geq f(x)\}$}{25}{subsubsection.2.10.1}%
\contentsline {subsubsection}{\numberline {2.10.2}Lemma: $f$ is convex function $\Leftrightarrow $ ${epi}(f)$ is a convex set}{25}{subsubsection.2.10.2}%
\contentsline {subsubsection}{\numberline {2.10.3}Jensen's Inequality: $f(\DOTSB \sum@ \slimits@ _{i=1}^k\lambda _i x_i)\leq \DOTSB \sum@ \slimits@ _{i=1}^k\lambda _if(x_i)$}{25}{subsubsection.2.10.3}%
\contentsline {subsection}{\numberline {2.11} Subgradients of Convex Functions}{26}{subsection.2.11}%
\contentsline {subsubsection}{\numberline {2.11.1}Sub-gradient $\vec {d}$: $f(\vec {x})\geq f(\vec {x}^*)+\vec {d}\cdot (\vec {x}-\vec {x}^*), \forall \vec {x}\in C$}{26}{subsubsection.2.11.1}%
\contentsline {subsubsection}{\numberline {2.11.2}Sub-differential: set of all sub-gradient}{27}{subsubsection.2.11.2}%
\contentsline {subsubsection}{\numberline {2.11.3}More examples}{28}{subsubsection.2.11.3}%
\contentsline {section}{\numberline {3}Geometric Programming (GP)}{29}{section.3}%
\contentsline {subsection}{\numberline {3.1}Arithmetic Mean-Geometric Mean Inequality (A-G inequality) $\delta _1x_2+\delta _2x_2+\cdots +\delta _nx_n\geq x_1^{\delta _1}x_2^{\delta _2}\cdots x_n^{\delta _n}$}{29}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Unconstrained Geometric Programs}{30}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}Def: Posynomial}{30}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}General Strategy: A-G inequality}{31}{subsubsection.3.2.2}%
\contentsline {subsubsection}{\numberline {3.2.3}Dual of the Unconstrained GP}{31}{subsubsection.3.2.3}%
\contentsline {section}{\numberline {4}Polynomial Interpolation}{33}{section.4}%
\contentsline {subsection}{\numberline {4.1}Method 1: $M\vec {a}=\vec {y}$}{33}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Method 2: Lagrange Interpolation Formula}{34}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Lines of Best Fit}{34}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Least-Square Problem (Overconstrainted $A \vec {x}= \vec {b}$)}{35}{subsection.4.4}%
\contentsline {subsubsection}{\numberline {4.4.1}Lemma: closest point $\Leftrightarrow $ $(A\vec {x}^*-\vec {y})\bot \vec {a},\ \forall \vec {a}\in V$}{35}{subsubsection.4.4.1}%
\contentsline {subsubsection}{\numberline {4.4.2}Theorem: $\vec {x}^*=(A^TA)^{-1}A^T\vec {y}=A^+ \vec {y}$}{35}{subsubsection.4.4.2}%
\contentsline {subsubsection}{\numberline {4.4.3}Def: Projection Matrix: $P=AA^+$; Projection of $\vec {y}$ on $V$: $A \vec {x}^*=P \vec {y}$}{36}{subsubsection.4.4.3}%
\contentsline {subsubsection}{\numberline {4.4.4}Special Case: Projection on vector ${Proj}_{\vec {a}}(\vec {y})=\frac {(\vec {a}\cdot \vec {y})\vec {a}}{\|\vec {a}\|^2}$}{36}{subsubsection.4.4.4}%
\contentsline {subsubsection}{\numberline {4.4.5}Theorem: Projection Matrix $=$ Sum of outer products of orthonormal basis}{36}{subsubsection.4.4.5}%
\contentsline {subsubsection}{\numberline {4.4.6}Corollary: $Q$ has orthonormal columns $\Rightarrow $ $\vec {x}^*=Q^T \vec {y}$. ($Q^+=Q^T$)}{37}{subsubsection.4.4.6}%
\contentsline {subsubsection}{\numberline {4.4.7}The Gram-Schmidt process}{37}{subsubsection.4.4.7}%
\contentsline {subsection}{\numberline {4.5}Minimum-norm problems (Underconstrainted $A \vec {x}= \vec {b}$)}{38}{subsection.4.5}%
\contentsline {subsubsection}{\numberline {4.5.1}Applying the least-squares technique}{38}{subsubsection.4.5.1}%
\contentsline {subsubsection}{\numberline {4.5.2}The short cut method}{40}{subsubsection.4.5.2}%
\contentsline {subsubsection}{\numberline {4.5.3}The short cut method with $H$-norm}{40}{subsubsection.4.5.3}%
\contentsline {section}{\numberline {5}The Closest Point: Projection}{42}{section.5}%
\contentsline {subsection}{\numberline {5.1}Set Theory Basis}{42}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Def: Projection $[z]^\&$}{42}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}\underline {Unique} projection $[z]^\&$ on \underline {closed convex} subset of $\mathbb {R}^n$}{43}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Obtuse Angle Criterion: $[z]^\&$ is projection $\Leftrightarrow $ $(z-[z]^\&)^T(y-[z]^\&)\leq 0, \forall y\in \&$}{43}{subsection.5.4}%
\contentsline {subsubsection}{\numberline {5.4.1}Special Case (Linear subspace): Orthogonality Principle $(z-[z]^\&)^Tx= 0,\forall x\in \&$}{45}{subsubsection.5.4.1}%
\contentsline {subsection}{\numberline {5.5}Prop: Projection is Non-expansive $\|[x]^\&-[z]^\&\|\leq \|x-z\|,\forall x,z\in \mathbb {R}^n$}{45}{subsection.5.5}%
\contentsline {subsection}{\numberline {5.6}The Separation Theorem}{46}{subsection.5.6}%
\contentsline {subsection}{\numberline {5.7}Bolzano-Weierstrass theorem}{47}{subsection.5.7}%
\contentsline {subsubsection}{\numberline {5.7.1}Sequence Convergence}{47}{subsubsection.5.7.1}%
\contentsline {subsubsection}{\numberline {5.7.2}Bolzano-Weierstrass Theorem: $\exists $ subsequence converges to $\vec {x}^*\in S$}{47}{subsubsection.5.7.2}%
\contentsline {subsubsection}{\numberline {5.7.3}Extreme Value Theorem: continuous $f$ compact set $\rightarrow \mathbb {R}$ has global-min}{47}{subsubsection.5.7.3}%
\contentsline {subsubsection}{\numberline {5.7.4}Support Theorem: $z\in bd(C)$, $\exists \vec {u}$ s.t. $\vec {u}\cdot \vec {x}\leq \vec {u}\cdot \vec {z}, \forall \vec {x}\in C$}{48}{subsubsection.5.7.4}%
\contentsline {section}{\numberline {6}Constrained Optimization}{48}{section.6}%
\contentsline {subsection}{\numberline {6.1}Perturbation of Constraints}{49}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Theorem: convex program $\Rightarrow $ $MP(\vec {z})$ is a convex function on convex domain}{49}{subsubsection.6.1.1}%
\contentsline {subsection}{\numberline {6.2}Karush-Kuhn-Tucker theorem}{50}{subsection.6.2}%
\contentsline {subsubsection}{\numberline {6.2.1}Def: $P$ is super-consistent (Slater's condition): $\exists \vec {x}^*\in S$ s.t. $\vec {g}(\vec {x}^*)<\vec {0}$}{50}{subsubsection.6.2.1}%
\contentsline {subsubsection}{\numberline {6.2.2}Lemma: $P$ is super-consistent $\Rightarrow $ $\exists $ sensitivity vector $\vec {\lambda }\geq 0$ s.t. $MP(\vec {z})\geq MP(\vec {0})-\vec {\lambda }\cdot \vec {z},\forall \vec {z}$}{50}{subsubsection.6.2.2}%
\contentsline {subsubsection}{\numberline {6.2.3}Goalposts Lemma: $\vec {x}^{(0)}$ is feasible for $P(\vec {g}(\vec {x}^{(0)}))$ and $MP(\vec {g}(\vec {x}^{(0)}))\leq f(\vec {x}^{(0)})$}{51}{subsubsection.6.2.3}%
\contentsline {subsubsection}{\numberline {6.2.4}KKT Theorem: Saddle Point Form}{51}{subsubsection.6.2.4}%
\contentsline {subsubsection}{\numberline {6.2.5}KKT Theorem: Gradient Form}{53}{subsubsection.6.2.5}%
\contentsline {subsubsection}{\numberline {6.2.6}Relationship between KKT and Optimal Solution}{54}{subsubsection.6.2.6}%
\contentsline {subsection}{\numberline {6.3}KKT Duality}{55}{subsection.6.3}%
\contentsline {subsubsection}{\numberline {6.3.1}Thm: $h(\vec {\lambda })=\inf _{\vec {x}\in S}\{L(\vec {x},\vec {\lambda })\}\leq h(\vec {\lambda ^*})=f(\vec {x}^*)$}{55}{subsubsection.6.3.1}%
\contentsline {subsubsection}{\numberline {6.3.2}KKT Duality}{56}{subsubsection.6.3.2}%
\contentsline {subsubsection}{\numberline {6.3.3}The Duality Gap}{56}{subsubsection.6.3.3}%
\contentsline {section}{\numberline {7}Constrained Geometric Programming}{56}{section.7}%
\contentsline {section}{\numberline {8}Optimization with Equality Constraints}{56}{section.8}%
\contentsline {subsection}{\numberline {8.1}Basic}{56}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Lagrange Mutiplier Theorem}{57}{subsection.8.2}%
\contentsline {subsubsection}{\numberline {8.2.1}First-order necessary condition: $\exists \lambda , \nabla f(x^*)+\DOTSB \sum@ \slimits@ _{i=1}^m\lambda _i \nabla h_i(x^*)=0$}{57}{subsubsection.8.2.1}%
\contentsline {subsubsection}{\numberline {8.2.2}Second-order necessary condition: $z^T\left (\nabla ^2 f(x^*)+\DOTSB \sum@ \slimits@ _{i=1}^m\lambda _i \nabla ^2 h_i(x^*)\right )z\geq 0,\forall z\in V(x^*)$}{58}{subsubsection.8.2.2}%
\contentsline {subsubsection}{\numberline {8.2.3}Sufficient Condition: $\exists \lambda $ 1. $\nabla f(x^*)+\DOTSB \sum@ \slimits@ _{i=1}^m\lambda _i \nabla h_i(x^*)=0$ 2. $z^T\big (\nabla ^2 f(x^*)+\DOTSB \sum@ \slimits@ _{i=1}^m\lambda _i \nabla ^2 h_i(x^*)\big )z> 0,\forall z\in V(x^*),z\neq 0$}{59}{subsubsection.8.2.3}%
\contentsline {subsubsection}{\numberline {8.2.4}Lagrangian Function}{60}{subsubsection.8.2.4}%
\contentsline {subsubsection}{\numberline {8.2.5}Example}{60}{subsubsection.8.2.5}%
\contentsline {subsubsection}{\numberline {8.2.6}Sensitivity Analysis $f(x^*(u))=f(x^*)-\lambda ^Tu+O(\|u\|)$}{61}{subsubsection.8.2.6}%
\contentsline {subsubsection}{\numberline {8.2.7}Linear Constraints}{62}{subsubsection.8.2.7}%
\contentsline {section}{\numberline {9}Optimization with Inequality Constraints}{64}{section.9}%
\contentsline {subsection}{\numberline {9.1}Basic}{64}{subsection.9.1}%
\contentsline {subsubsection}{\numberline {9.1.1}Active vs. Inactive Inequality Constraints}{64}{subsubsection.9.1.1}%
\contentsline {subsubsection}{\numberline {9.1.2}ICP $\rightarrow $ ECP}{64}{subsubsection.9.1.2}%
\contentsline {subsubsection}{\numberline {9.1.3}Intuition $\mu _j\geq 0, \forall j\in A(x^*)$}{65}{subsubsection.9.1.3}%
\contentsline {subsubsection}{\numberline {9.1.4}Complementary Slackness}{65}{subsubsection.9.1.4}%
\contentsline {subsection}{\numberline {9.2}Karush–Kuhn–Tucker (KKT) Necessary Conditions}{65}{subsection.9.2}%
\contentsline {subsection}{\numberline {9.3}Karush–Kuhn–Tucker (KKT) Sufficient Conditions}{67}{subsection.9.3}%
\contentsline {subsection}{\numberline {9.4}General Sufficiency Condition}{70}{subsection.9.4}%
\contentsline {subsection}{\numberline {9.5}Barrier Method}{71}{subsection.9.5}%
\contentsline {subsection}{\numberline {9.6}An Exmaple Using KKT or Barrier}{72}{subsection.9.6}%
\contentsline {subsubsection}{\numberline {9.6.1}Solution using KKT conditions}{72}{subsubsection.9.6.1}%
\contentsline {subsubsection}{\numberline {9.6.2}Solution using logarithmic barrier}{73}{subsubsection.9.6.2}%
\contentsline {subsection}{\numberline {9.7}Penalty Method (For ECP)}{73}{subsection.9.7}%
\contentsline {section}{\numberline {10}Duality}{74}{section.10}%
\contentsline {subsection}{\numberline {10.1}Weak Duality Theorem: $\max _{(\lambda ,\mu )\in G}D(\lambda ,\mu )\leq \min _{x\in F}f(x)$}{75}{subsection.10.1}%
\contentsline {subsection}{\numberline {10.2}Strong Duality Theorem: under some conditions, $\max _{(\lambda ,\mu )\in G}D(\lambda ,\mu )= \min _{x\in F}f(x)$}{76}{subsection.10.2}%
\contentsline {subsubsection}{\numberline {10.2.1}Slater's sufficient condition for strong duality}{77}{subsubsection.10.2.1}%
\contentsline {subsubsection}{\numberline {10.2.2}Example}{78}{subsubsection.10.2.2}%
\contentsline {subsection}{\numberline {10.3}Dual of Linear Program}{78}{subsection.10.3}%
\contentsline {section}{\numberline {11}Strongly Convexity}{79}{section.11}%
\contentsline {subsection}{\numberline {11.1}$\mu $-Strongly Convex: $ \langle \nabla f(w)-\nabla f(v), w-v\rangle \geq \mu \|w-v\|^{2}$}{79}{subsection.11.1}%
\contentsline {subsection}{\numberline {11.2}$\mu $-strongly convex $\Leftrightarrow \nabla ^{2} f(x) \succeq \mu I\Leftrightarrow $"$f(x)-\frac {m}{2}\|x\|^2$ is convex"}{80}{subsection.11.2}%
\contentsline {subsection}{\numberline {11.3}Lemma: Strongly convexity $\Rightarrow $ Strictly convexity}{80}{subsection.11.3}%
\contentsline {subsection}{\numberline {11.4}Lemma: $\nabla ^2 f(x)\succeq mI$ $\Rightarrow $ $f(y)\geq f(x)+\nabla f(x)^T(y-x)+\frac {m}{2}\|y-x\|^2$}{80}{subsection.11.4}%
\contentsline {section}{\numberline {12}Lipschitz Gradient ($L$-Smooth)}{81}{section.12}%
\contentsline {subsection}{\numberline {12.1}Theorem: $-MI\preceq \nabla ^2 f(x)\preceq MI$ $\Rightarrow $ $f$ is $M$-smooth}{81}{subsection.12.1}%
\contentsline {subsection}{\numberline {12.2}Descent Lemma: $f$ is $L$-smooth $\Rightarrow $ $f(y)\leq f(x)+\nabla f(x)^T(y-x)+\frac {L}{2}\|y-x\|^2$}{82}{subsection.12.2}%
\contentsline {subsection}{\numberline {12.3}Co-coercivity Condition: $(\nabla f(x)-\nabla f(y))^T(x-y)\geq \frac {1}{L}\|\nabla f(x)-\nabla f(y)\|^2$}{83}{subsection.12.3}%
