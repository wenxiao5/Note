%!TEX program = xelatex
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{authblk}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{indentfirst}
\usepackage{amssymb}
\linespread{1.6}\setlength{\footskip}{20pt}\setlength{\parindent}{0pt}
\usetikzlibrary{shapes,snakes}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\DeclareMathOperator{\col}{col}
\usepackage{booktabs}
\newtheorem{theorem}{Theorem}
\newtheorem{note}{Note}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{claim}{Claim}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem{corollary}{Corollary}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\newcommand{\code}{	exttt}
\geometry{a4paper,scale=0.8}
\title{Inference and Learning}
\author[*]{Wenxiao Yang}
\affil[*]{Department of Mathematics, University of Illinois at Urbana-Champaign}
\date{2022}
\begin{document}
\maketitle
\tableofcontents
\newpage


\section{Statistical Inference}

\subsection{Basics}
Given an observation $x\in X$, we want to estimate an unknown state $\theta \in S$ (not necessarily random). The $\theta$ can form $x$ with $P_\theta(x)$. We use decision rule $\delta (x)$ to form an action (estimation of $\theta$) $a=\hat{\theta}$.

\textbf{Example:}
\begin{enumerate}[(1)]
    \item Binary hypothesis testing (detection) when $S=\{0,1\}$ e.g. $P_0\sim N(0,\sigma^2), P_1\sim N(\mu,\sigma^2)$
    \item Multiple hypothesis testing (classification) when $S=\{1,2,...,n\}$
    \item (Estimation) when $S=\mathbb{R}$ e.g. $P_\theta\in N(\theta,\sigma^2)$
\end{enumerate}

\subsection{Decision Rule Examples}
\subsubsection*{Binary HT Example}
For the example Binary HT, $P_0\sim N(0,\sigma^2), P_1\sim N(\mu,\sigma^2)$: decision rule $\delta: \mathbb{R} \rightarrow \{0,1\}$

We can find a $\tau$ such that $\delta(x)=\left\{\begin{matrix}
    1,&x\ge \tau\\
    0,& else
\end{matrix}\right.=\mathbf{1}_{x\geq \tau}$. Howe to choose $\tau$?

Type-I error probability: probability that $\theta$ is $0$ but receive $\delta(x)=1$. $$P_I=P_0\{\delta(x)=1\}=P_0\{x\geq \tau\}=Q\left(\frac{\tau}{\sigma}\right)$$
Type-II error probability: probability that $\theta$ is $1$ but receive $\delta(x)=0$. $$P_{II}=P_1\{\delta(x)=0\}=P_1(x<\tau)=Q(\frac{\mu-\tau}{\sigma})$$

Both $P_I$ and $P_{II}$ depends on $\tau$. $Q(t)=\int_t^\infty\frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}}dx$

For $\tau=\frac{\mu}{2}$, $P_I=P_{II}=Q\left(\frac{\mu}{2\sigma}\right)$

\subsubsection*{Multiple HT Example}
Consider three state $S=\{1,2,3\}$.
We can find a $\tau$ such that $\delta(x)=\left\{\begin{matrix}
    1,&x< \tau_1\\
    2,& \tau_1\leq x\leq \tau_2\\
    3,& x>\tau_2
\end{matrix}\right.=\mathbf{1}_{x\geq \tau}$.

\textit{Conditional Error Probabilities:} probability that $\theta$ is $i$ but receive $\delta(x)=j$ (6 types in this example) $$P_i\{\delta(x)=j\}, \forall i\neq j$$

\subsubsection*{Estimation Example}
Ex: $P_\theta\sim N(\theta,\sigma^2)$. Perform $\delta(x)=\hat{\theta}$ by using mean-squared error (MSE):
$$MSE= \mathbb{E}_\theta \left[(\delta(x)-\theta)^2\right],\theta\in \mathbb{R}$$

\subsection{Maximum-Likelihood Principle (state is norandom)}
Maximum-Likelihood Principle $$\hat{\theta}=\argmax_{\theta\in S}P_{\theta}(x)=\argmax_{\theta\in S}\ln P_{\theta}(x)$$
Applied to the binary example: $P_0\sim N(0,\sigma^2), P_1\sim N(\mu,\sigma^2)$.

$P_0(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{x^2}{2\sigma^2}}, P_1(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$. $\ln P_0(x)=c-\frac{x^2}{2\sigma^2}$, $\ln P_1(x)=c-\frac{(x-\mu)^2}{2\sigma^2}$.

Then, the rule can become $$\hat{\theta}=\left\{\begin{matrix}
    0,&x^2<(x-\mu)^2\\
    1,&else
\end{matrix}\right.=\mathbf{1}_{x^2\geq (x-\mu)^2}=\mathbf{1}_{x\geq \frac{\mu}{2}}$$

\subsubsection*{Vector Observations}
Observations $X=\left(x_1,x_2,...,x_n\right)$, where i.i.d. $x_i\sim P_\theta$. Then $$P_\theta(X)=\prod_{i=1}^n P_\theta(x_i),\ \ln P_\theta(X)=\sum_{i=1}^n\ln P_\theta(x_i)$$
$\ln P_0(x)=cn-\frac{\sum_{i=1}^n x_i^2}{2\sigma^2}$, $\ln P_1(x)=cn-\frac{\sum_{i=1}^n(x_i-\mu)^2}{2\sigma^2}$.

Then, the rule can become $$\hat{\theta}=\left\{\begin{matrix}
    0,&\sum_{i=1}^nx_i^2<\sum_{i=1}^n(x_i-\mu)^2\\
    1,&else
\end{matrix}\right.=\mathbf{1}_{\sum_{i=1}^nx_i^2\geq \sum_{i=1}^n(x_i-\mu)^2}=\mathbf{1}_{\bar{x}\geq \frac{\mu}{2}}$$
where $\bar{x}=\frac{1}{n}\sum_{i=1}^nx_i$. Under both $H_0$ and $H_1$, $\bar{x}\sim N(0,\frac{\sigma^2}{n})$.

Then, type I error prob and type II error prob are the same $$P_I=P_0\{\bar{x}\geq \frac{\mu}{2}\}=P_{II}=P_1\{\bar{x}< \frac{\mu}{2}\}=Q\left(\frac{\mu\sqrt{n}}{2\sigma}\right)$$

\subsubsection*{Esitimation $S=\mathbb{R}$}
To estimate $\theta$ when $S=\mathbb{R}$
\begin{equation}
    \begin{aligned}
        &\max_{\theta\in \mathbb{R}}\sum_{i=1}^n\ln P_\theta(x_i)\\
        &\Leftrightarrow \max_{\theta\in \mathbb{R}} \left[cn-\frac{\sum_{i=1}^n(x_i-\theta)^2}{2\sigma^2}\right]\\
        &\Leftrightarrow \max_{\theta\in \mathbb{R}} \sum_{i=1}^n(x_i-\theta)^2 \Rightarrow \hat{\theta}=\bar{x}
    \end{aligned}
    \nonumber
\end{equation}

Then, with $\bar{x}\sim N(\theta,\frac{\sigma^2}{n})$, the $$MSE_\theta=\mathbb{E}_\theta\left(\bar{x}-\theta\right)^2=\frac{\sigma^2}{n}$$

\subsection{Bayesian Decision Rule (state is random)}
\subsubsection{Rules}
Prior probability distribution $\pi(\theta)$,

\underline{Loss/cost function} with action (estimation) $a$ is $l(a,\theta)$. e.g.
\begin{enumerate}
    \item (binary HT) Hamming/zero-one loss $l(a=\hat{\theta},\theta)=\mathbf{1}_{a\neq \theta}$
    \item (estimation) Squared error loss $l(a=\hat{\theta},\theta)=(a-\theta)^2$; Absolute error loss $l(a,\theta)=|a-\theta|$.
\end{enumerate}

\textbf{Risk of decision rule $\delta$:} $$R(\delta)=\mathbb{E}\left(l(\delta(X),\theta)\right)$$ where $(X,\theta)$ are random with prob $\pi(\theta),P_\theta$

\textbf{Note: to help be consistent with machine learning notations, we use $y$ to substitute $\theta$.}

The joint probability $P(x,y)=\pi(y)P_y(x)=P(x)\pi(y|x)$.

\textbf{Bayes rule}
$$\delta_B=\argmin_\delta R(\delta)$$
\underline{Derive Bayes rule}
\begin{equation}
    \begin{aligned}
        R(\delta)&=\int_x\int_y P(x,y) l(\delta(x),y) dy dx\\
        &=\int_x P(x)\int_y \pi(y|x) l(\delta(x),y) dy dx\\
    \end{aligned}
    \nonumber
\end{equation}
Solve optimization problem:
\begin{equation}
    \begin{aligned}
        \min_\delta \int_x P(x)\int_y \pi(y|x) l(\delta(x),y) dy dx
    \end{aligned}
    \nonumber
\end{equation}
\begin{center}
    \fcolorbox{black}{gray!10}{\parbox{.9\linewidth}{this problem can be transformed into optimization problems for each $x\in S$
    \begin{equation}
        \begin{aligned}
            \min_{\delta(x)} \int_y \pi(y|x) l(\delta(x),y) dy
        \end{aligned}
        \nonumber
    \end{equation}}}
\end{center}
\underline{The problem becomes to compute $\pi(y|x)$}. From $P(x,y)=\pi(y)P_y(x)=P(x)\pi(y|x)$, we know $$\pi(y|x)=\frac{\pi(y)P_y(x)}{P(x)}$$

\subsubsection{Maximum A Posteriori (MAP) Decision Rule (Binary example)}
\begin{example}
    Hamming/zero-one loss $l(a,y)=\mathbf{1}_{a\neq y}$
\end{example}

\textbf{Maximum A Posteriori (MAP) Decision Rule}:

Optimization problem is $\delta(x)=\argmin_{a} \sum_{y=0,1} \pi(y|x) \mathbf{1}_{a\neq y} dy=\argmax_{y\in\{0,1\}}\pi(y|x)$

Likelihood ratio: $L(x)=\frac{P_1(x)}{P_0(x)}$

Likelihood ratio test: threshold $\tau=\frac{\pi(0)}{\pi(1)}$. If $L(x)>\tau$ accept $H_1$ (equivalent to $P_1(x)\pi(1)>P_0(x)\pi(0)$ which is also equivalent to comparing $\pi(y|x)$).

In this rule the whole optimization problem also goes to
$$R(\delta_{MAP})=\int_x P(x)\min\{\pi(1|x),\pi(0|x)\}dx$$

\subsubsection{Minimum Mean Squared Error (MMSE) Rule ($\mathbb{R}^n$ example)}
\begin{example}
    (estimation) Squared error loss $l(a,y)=(a-y)^2$.
\end{example}
\subsubsection*{Minimum Mean Squared Error (MMSE) Rule:}
Optimization problem is $\delta(x)=\argmin_{a} \int_{y} \pi(y|x) (a-y)^2 dy$
\begin{equation}
    \begin{aligned}
        0=\int_{y} \pi(y|x) (\delta_B(x)-y) dy=\delta_B(x)-\mathbb{E}\left[Y|X=x\right]
    \end{aligned}
    \nonumber
\end{equation}
\begin{equation}
    \begin{aligned}
        \Rightarrow \delta_B(x)=\mathbb{E}\left[Y|X=x\right]
    \end{aligned}
    \nonumber
\end{equation}
which is called \textbf{conditional mean estimation}.

In this rule the whole optimization problem also goes to
$$R(\delta_{MMSE})=\int_x P(x)\int_y \pi(y|x) (y-\mathbb{E}\left[Y|X=x\right])^2 dy dx=\mathbb{E}_X Var\left[Y|X=x\right]$$

\textbf{Gaussian case:}
If $X\in \mathbb{R}^n$ and $(Y,X)$ are jointly Gaussian, then the conditional mean is a linear function of x, also called linear MMSE estimator.
\begin{equation}
    \begin{aligned}
        \mathbb{E}\left[Y|X=x\right]=\mathbb{E}[Y]+Cov(Y,X)Cov(X)^{-1}(x-\mathbb{E}[X])
    \end{aligned}
    \nonumber
\end{equation}
and the posterior risk is independent of $x$:
\begin{equation}
    \begin{aligned}
        Var\left[Y|X=x\right]=Var[Y]-Cov(Y,X)Cov(X)^{-1}Cov(X,Y)
    \end{aligned}
    \nonumber
\end{equation}
\subsection{Comparison}
Maximum-Likelihood Principle (state is norandom): $\delta_{ML}(x)=\argmax_y P_y(x)$.

Maximum A Posteriori (MAP) Decision Rule (state is random): $\delta_{MAP}(x)=\argmax_y \pi(y|x)=\argmax_y \{\pi(y|x),P_y(x)\}$


\section{Machine Learning}
Instead of given a prior distribution of $Y$, we are given a \textbf{training set} $T=(X_i,Y_i)_{i=1}^n$ where i.i.d. $(X_i,Y_i)\sim P$. (Distribution $P$ is unknown).

Risk: $R(\delta)=\mathbb{E}_P\left[l(\delta(X),Y)\right]$

The ture optimal decision rule is $$\delta_B=\argmin_\delta \mathbb{E}_P\left[l(\delta(X),Y)\right]$$
which is can't be computed since we don't know how actually $P$ is.

\subsection{Empirical Risk Minimization (ERM)}
Instead of computing optimal decision rule with $P$, we compute the optimal decisioin rule in the training set:
$$\hat{\delta}_n=\argmin_\delta \frac{1}{n}\sum_{i=1}^nl(\delta(X_i),Y_i)$$
The corresponding risk is $R(\hat{\delta}_n)=\mathbb{E}_P\left[l(\hat{\delta}_n(X),Y)\right]$. $\Delta R(\hat{\delta}_n)=R(\hat{\delta}_n)- R(\delta)>0$ always holds.

\textbf{Consistency:} if $\Delta R(\hat{\delta}_n) \rightarrow 0$ as $n \rightarrow \infty$.

\subsubsection{Example: Linear MMSE (LMMSE) estimator}
Use the decision role in the class of $\delta(x)=wx$. To find the linear MMSE (LMMSE) estimation $\delta^*(x)=w^*x$:
\begin{equation}
    \begin{aligned}
        w^*=\argmin_{w}\mathbb{E}_P\left[(wX-Y)^2\right]=\frac{\mathbb{E}[XY]}{\mathbb{E}[X^2]}
    \end{aligned}
    \nonumber
\end{equation}
The rule that minimizes the \textbf{empirical risk} is
\begin{equation}
    \begin{aligned}
        \hat{w}=\argmin_{w}\frac{1}{n}\sum_{i=1}^n(wX_i-Y_i)^2=\frac{\frac{1}{n}\sum_{i=1}^nX_iY_i}{\frac{1}{n}\sum_{i=1}^nX_i^2}
    \end{aligned}
    \nonumber
\end{equation}
The risk of the optimal rule $\delta^*=w^*x$ is $R(\delta^*)$ and the empirical risk under rule $\hat{\delta}(x)=\hat{w}x$ is $R(\hat{\delta}(x))$. $R(\hat{\delta})>R(\delta^*)$ always holds, and $$R(\hat{\delta})\rightarrow R(\delta^*)\text{ as }n \rightarrow \infty$$
According to CLT:
\begin{equation}
    \begin{aligned}
        \sqrt{n}\left(\frac{1}{n}\sum_iX_iY_i- \mathbb{E}(XY)\right) &\stackrel{d}{\longrightarrow} N(0,\sigma^2)\\
        \sqrt{n}\left(\frac{1}{n}\sum_iX_i^2- \mathbb{E}(X^2)\right) &\stackrel{d}{\longrightarrow} N(0,\sigma^2)
    \end{aligned}
    \nonumber
\end{equation}
Then,
\begin{equation}
    \begin{aligned}
        \frac{1}{n}\sum_iX_i^2=\mathbb{E}(X^2)+O(\frac{1}{\sqrt{n}})\\
        \frac{1}{n}\sum_iX_iY_i=\mathbb{E}(XY)+O(\frac{1}{\sqrt{n}})\\
    \end{aligned}
    \nonumber
\end{equation}
which means the error of estimators
\begin{equation}
    \begin{aligned}
        \hat{w}=\frac{\mathbb{E}(X^2)+O(\frac{1}{\sqrt{n}})}{\mathbb{E}(XY)+O(\frac{1}{\sqrt{n}})}=w^*+O(\frac{1}{\sqrt{n}})
    \end{aligned}
    \nonumber
\end{equation}
$$\hat{w}-w^*=O(\frac{1}{\sqrt{n}})$$
and the error of the risks:
\begin{equation}
    \begin{aligned}
        R(\hat{\delta})-R(\delta^*)&=\mathbb{E}_P[\hat{w}X-Y]^2-\mathbb{E}_P[w^*X-Y]^2\\
        &=\mathbb{E}_P[(\hat{w}-w^*)X+w^*X-Y]^2-\mathbb{E}_P[w^*X-Y]^2\\
        &=\mathbb{E}_P[(\hat{w}-w^*)X]^2+2(\hat{w}-w^*)\mathbb{E}_P[X(w^*X-Y)]\\
        &=(\hat{w}-w^*)\mathbb{E}_P(X^2)=O\left(\frac{1}{n}\right)
    \end{aligned}
    \nonumber
\end{equation}

\begin{center}
    \fcolorbox{black}{gray!10}{\parbox{.9\linewidth}{\textbf{\underline{Complexity}:}
    \begin{definition}
        A sequence $f(n)$ is $O(1)$ if $\lim_{n \rightarrow \infty}f(n)<\infty$.
    \end{definition}
    
    \begin{definition}
        A sequence $f(n)$ is $O(g(n))$ if $\frac{f(n)}{g(n)}$ is $O(1)$.
    \end{definition}
    
    \begin{definition}
        A sequence $f(n)$ is $o(1)$ if $\lim_{n \rightarrow \infty}\sup f(n)=0$.
    \end{definition}
    
    \begin{definition}
        A sequence $f(n)$ is $o(g(n))$ if $\lim_{n \rightarrow \infty}\sup \frac{f(n)}{g(n)}=0$.
    \end{definition}
    
    \begin{definition}
        A sequence $f(n)$ is \underline{asymptotic} to $g(n)$ if $\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)}=1$. (This is denoted by $f(n)\sim g(n)$ as $a \rightarrow \infty$)
    \end{definition}
    }}
\end{center}

\subsubsection{Penalized ERM}
$\delta(x)=\sum_{j=1}^Jw_jx^j$

Pick $J=d$ and use ERM with $d$ dimensional $w$: $$\argmin_{w\in \mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n[w^TX_i-Y_i]^2$$

Approach 1: Fix $d<<n$, use ERM.

Approach 2: (\textbf{Penalized ERM}) $$\min_\delta [R_{emp}(\delta)+J(\delta)]$$ ($J(\delta)$ is regularization (penalty) term)

\subsection{Stochastic Approximation}
Robbins and Monro (95)

\underline{Problem:} Find a root of function $h(x)$. ($f(x)=0$)

We do not observe $h(x)$ directly, but we observe $Y\sim P_x$ with
\begin{enumerate}[(1)]
    \item $\mathbb{E}[Y|X=x]=h(x)$
    \item $(Y|X=x)-h(x)$ is bounded
\end{enumerate}
\begin{example}
    $Y=X+Z$ with $\mathbb{E}[Z]=0$ and $Z$ is bounded.
\end{example}
Assumptions: 1. $h'(x^*)>0$; 2. $x^*$ is the unique root of $h$.

\textbf{SA Algorithm}
\begin{enumerate}[$\bullet$]
    \item Prick Sequence $\{a_n\}$ such that $\sum_{n=1}^\infty a_n=\infty$ and $\sum_{n=1}^\infty a^2_n<\infty$ (should converge to $0$ but not too quick) e.g. $a_n=n^{-\alpha}$ when $\alpha\in (\frac{1}{2},1]$.
    \item Initialize $X_1$
    \item Update for $n=1,2,...$, $Y_n\sim P(\cdot|X=X_n)$ $$X_{n+1}=X_n-a_n Y_n$$ until convergence.
\end{enumerate}

\textbf{\underline{Performance}}: the root mean squared error (RMSE) $e_n=\sqrt{\mathbb{E}[(X_n-x^*)^2]}$.

Averaging: $\bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i=\frac{X_n}{n}+\bar{X}_{n-1}\frac{n-1}{n}$.(nicer graph)


\begin{theorem}
    Under these assumptions $$X_n \stackrel{m.s.}{\longrightarrow} x^*\text{ as }n \rightarrow \infty$$ i.e., $\mathbb{E}(X_n-x^*)^2 \rightarrow 0$ as $n \rightarrow \infty$.
\end{theorem}

\begin{example}
    Let $h(x) = x$ and $I = [-1,1]$, in which case $x^* = 0$. $Y_n=X_n+Z_n$ where noise $Z_n$ is independent of $Y_n$ with $\mathbb{E}[Z_n]=0,Var(Z_n)=1$ and $Z_n$ is bounded.
\end{example}
Then,
    \begin{equation}
        \begin{aligned}
            X_{n+1}&=X_n-a_n(X_n+Z_n)\\
            &=(1-a_n)X_n-a_n Z_n
        \end{aligned}
        \nonumber
    \end{equation}
The MSE,
\begin{equation}
    \begin{aligned}
        e_{n+1}^2&=\mathbb{E}(X_{n+1}-x^*)^2=\mathbb{E}(X_{n+1})^2\\
        &=\mathbb{E}[(1-a_n)X_n-a_n Z_n]^2\\
        &=(1-a_n)^2\mathbb{E}X_n^2+a_n^2\mathbb{E}Z_n^2\\
        &=(1-a_n)^2e_n^2+a_n^2
    \end{aligned}
    \nonumber
\end{equation}
Pick $a_n=n^{-\alpha}$, where $\alpha\in (\frac{1}{2},1]$
\begin{equation}
    \begin{aligned}
        \Rightarrow e_{n+1}^2=(1-n^{-\alpha})^2e_n^2+n^{-2\alpha}
    \end{aligned}
    \nonumber
\end{equation}
\begin{center}
    \fcolorbox{black}{gray!10}{\parbox{.9\linewidth}{Guess: $e_n=cn^{-\beta}+H.O.T$}}
\end{center}


\end{document}