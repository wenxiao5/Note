\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Statistical Inference}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Basics}{4}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Decision Rule Examples}{4}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Maximum-Likelihood Principle (state is norandom)}{5}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Bayesian Decision Rule (state is random)}{6}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Rules}{6}{subsubsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Maximum A Posteriori (MAP) Decision Rule (Binary example)}{7}{subsubsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Minimum Mean Squared Error (MMSE) Rule ($\mathbb  {R}^n$ example)}{7}{subsubsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Comparison}{8}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Machine Learning in Inference}{8}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Empirical Risk Minimization (ERM)}{9}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Example: Linear MMSE (LMMSE) estimator}{9}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Penalized ERM}{10}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Stochastic Approximation}{10}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Stochastic Gradient Descent (SGD)}{14}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}SGD Application to Empirical Risk Minimization (ERM)}{14}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Different Gradient Descent for ERM}{15}{subsubsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Constraints on Learning Problem}{15}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Stachastic Integradtion Methods}{17}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Deterministic Methods (Better in Low Dimension)}{17}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Riemann Integration}{17}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Trapezoidal Rule}{18}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) Riemann approximation; (b) Trapezoidal approximation.}}{18}{figure.1}\protected@file@percent }
\newlabel{}{{1}{18}{(a) Riemann approximation; (b) Trapezoidal approximation}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Multidimensional Integration}{18}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Two-dimensional integration using regular grid.}}{18}{figure.2}\protected@file@percent }
\newlabel{}{{2}{18}{Two-dimensional integration using regular grid}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Stachastic Methods (Better in High Dimension)}{19}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Classical Monte Carlo Integration}{19}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Importance Sampling}{19}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Bootstrap (not enough data)}{21}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Residual Bootstrap}{21}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Particle Filtering}{23}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Kalman Filtering}{23}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Particle Filtering}{23}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Hidden Markov Model}}{24}{figure.3}\protected@file@percent }
\newlabel{}{{3}{24}{Hidden Markov Model}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Bayesian Recursive Filtering}{24}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Particle Filter (bootstrap filter)}{24}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}}{25}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}EM Algorithm}{25}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Deep Learning}{26}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Parameters and Hyperparameters}{26}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Neural Network: Back Propagation Algorithm}{27}{subsection.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Simple Neural Network}}{27}{figure.4}\protected@file@percent }
\newlabel{}{{4}{27}{Simple Neural Network}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Activations}{27}{subsubsection.7.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Activations}}{28}{figure.5}\protected@file@percent }
\newlabel{}{{5}{28}{Activations}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Multilayer Neural Network}{29}{subsubsection.7.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Multilayer Neural Network}}{29}{figure.6}\protected@file@percent }
\newlabel{}{{6}{29}{Multilayer Neural Network}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}A Simple Example of Back Propagation Algorithm}{30}{subsubsection.7.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Two Independent Pathways}}{31}{figure.7}\protected@file@percent }
\newlabel{}{{7}{31}{Two Independent Pathways}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4}Back Propagation Algorithm}{31}{subsubsection.7.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.5}Other Methods}{33}{subsubsection.7.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Perceptron Algorithm}{33}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}General Idea}{33}{subsubsection.7.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Perceptron Output}}{34}{figure.8}\protected@file@percent }
\newlabel{}{{8}{34}{Perceptron Output}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Algorithm}{34}{subsubsection.7.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Perceptron}}{35}{figure.9}\protected@file@percent }
\newlabel{}{{9}{35}{Perceptron}{figure.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Limitations}{35}{subsubsection.7.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}ADAptive LInear NEuron (ADALINE)}{35}{subsection.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}General Idea}{35}{subsubsection.7.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces ADALINE}}{36}{figure.10}\protected@file@percent }
\newlabel{}{{10}{36}{ADALINE}{figure.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Widrow-Hoff Delta Rule}{36}{subsubsection.7.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Logistic Regression (Binary-class Output)}{37}{subsection.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Generative and Discriminative Classifiers}{37}{subsubsection.7.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}Sigmoid function}{37}{subsubsection.7.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.3}Cross-entropy Loss Function}{38}{subsubsection.7.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.4}Algorithm}{38}{subsubsection.7.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Softmax Regression (Multi-class Output)}{39}{subsection.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.6.1}Multi-Class Classification and Multi-Label Classification}{39}{subsubsection.7.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Multi-Class Classification}}{39}{figure.11}\protected@file@percent }
\newlabel{}{{11}{39}{Multi-Class Classification}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Multi-Label Classification}}{39}{figure.12}\protected@file@percent }
\newlabel{}{{12}{39}{Multi-Label Classification}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Examples of Activation Layer and Loss Choice}}{40}{figure.13}\protected@file@percent }
\newlabel{}{{13}{40}{Examples of Activation Layer and Loss Choice}{figure.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.6.2}One-hot Encoding}{40}{subsubsection.7.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces One-hot encoding}}{40}{figure.14}\protected@file@percent }
\newlabel{}{{14}{40}{One-hot encoding}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.6.3}Softmax function}{41}{subsubsection.7.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.6.4}Categorical Cross-entropy Loss Function}{41}{subsubsection.7.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7}Deep Feedforward Networks}{42}{subsection.7.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.7.1}Definition}{42}{subsubsection.7.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Deep Neural Network}}{42}{figure.15}\protected@file@percent }
\newlabel{}{{15}{42}{Deep Neural Network}{figure.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.7.2}Universal Approximation Theorem}{43}{subsubsection.7.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Universal Approximation Theorem}}{43}{figure.16}\protected@file@percent }
\newlabel{}{{16}{43}{Universal Approximation Theorem}{figure.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8} Mini-batch Optimization}{44}{subsection.7.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.8.1}Stochastic Gradient Descent (SGD) and Batch Gradient Descent (BGD)}{44}{subsubsection.7.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.8.2}Mini-Batch Gradient Descent (MBGD)}{44}{subsubsection.7.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces BGD and SGD}}{45}{figure.17}\protected@file@percent }
\newlabel{}{{17}{45}{BGD and SGD}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces SGD and MBGD}}{46}{figure.18}\protected@file@percent }
\newlabel{}{{18}{46}{SGD and MBGD}{figure.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Comparison of Approaches}}{46}{figure.19}\protected@file@percent }
\newlabel{}{{19}{46}{Comparison of Approaches}{figure.19}{}}
\gdef \@abspage@last{46}
